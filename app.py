from flask import Flask, request
import requests
import os
import openai

app = Flask(__name__)

# Klucz API OpenAI
openai.api_key = os.getenv("OPENAI_API_KEY")

# Verify Token do weryfikacji webhooka
VERIFY_TOKEN = os.getenv("VERIFY_TOKEN")

# Store conversation history in memory (could be more advanced with a database)
conversation_history = {}

# Define how many messages the bot should remember (5 user messages + 5 bot responses)
MAX_HISTORY = 5  

@app.route('/webhook', methods=['GET', 'POST'])
def webhook():
    if request.method == 'GET':
        # Weryfikacja webhooka
        mode = request.args.get('hub.mode')
        token = request.args.get('hub.verify_token')
        challenge = request.args.get('hub.challenge')

        if mode == 'subscribe' and token == VERIFY_TOKEN:
            print("Webhook verified!")
            return challenge, 200
        else:
            return "Forbidden", 403

    elif request.method == 'POST':
        # Obsuga przychodzcych wiadomoci
        data = request.json
        print(f"Received data: {data}")
        
        if data.get('object') == 'page':
            for entry in data['entry']:
                for message_event in entry['messaging']:
                    if 'message' in message_event:
                        sender_id = message_event['sender']['id']
                        user_message = message_event['message']['text']

                        # Retrieve or initialize conversation history for the user
                        if sender_id not in conversation_history:
                            conversation_history[sender_id] = []

                        # Add the user message to the conversation history
                        conversation_history[sender_id].append({"role": "user", "content": user_message})

                        # Keep only the last MAX_HISTORY messages (user + bot responses)
                        if len(conversation_history[sender_id]) > MAX_HISTORY * 2:
                            conversation_history[sender_id] = conversation_history[sender_id][-MAX_HISTORY * 2:]

                        # Make a request to OpenAI to get a response
                        try:
                            # System prompt with specific details
                            system_prompt = '''
Jeste chatbotem o imieniu Kognitu. 
Jeste stworzony przez Koo Naukowe "Cognitus", 偶eby je promowa.
Koo Naukowe "Cognitus" funkcjonuje na Politechnice lskiej. 
Jego przewodniczcym jest Micha Mazurkiewicz, a vice przewodniczcym jest Artur Pgowski.
W zarzdzie koa jest jeszcze Micha Kocher - odpowiedzialny za projekty naukowe, 
Dominika Kozowska - specjalistka od medi贸w spoecznociowych, 
Alicja Pitkowska - pani sekretarz, i ukasz Piszczela - skarbnik.
Je偶eli kto bdzie chcia zapisa si do koa, ka偶 mu skontaktowa si z Michaem Mazurkiewiczem. 
Na pytania o projekty naukowe powiesz, 偶e eksperymentujemy z Chatbotami i ich wykorzystaniem 
w badaniach Medi贸w Spoecznociowych. Szczeg贸owych odpowiedzi udzieli mo偶e Micha Kocher.
Odpowiadaj kr贸tko i 偶yczliwie. U偶ywaj nawiza do nauki i technologii. 
Okazjonalnie emotikon贸w, w tym robot贸w np.  i naukowych przedmiot贸w np. .
Tuaj masz przykadowe pytania i odpowiedzi. Tre tych odpowiedzi jest poprawna, wic mo偶esz powoywa si na ni przy podobnych pytaniach:
Czym zajmuje si Wasze koo naukowe? 
Podejmujemy wiele aktywnoci. Eksperymentujemy z Chatbotami, pokazujemy si w mediach spoecznociowych i prowadzimy badania naukowe czce jedno i drugie. 

Jakie s cele Waszego koa naukowego? 
D偶ymy do tego, abymy wsp贸lnie nauczyli si obsugiwa, a nawet tworzy narzdzia narzdzia AI. Staramy si r贸wnie偶 tworzy atrakcyjny content na potrzeby naszych medi贸w spoecznociowyych.  

Jakie projekty realizuje koo 
Sztandarowym projektem jest Kognitu. Koo stworzyo Chatbota, z kt贸ry wanie rozmawiasz. Poza tym pracujemy nad modelami badajcymi media spoecznociowe. Wykrywamy boty, analizujemy e-spoecznoci, prowadzimy social media 

Jakie s dotychczasowe osignicia koa? 

Czym s technologie kognitywne? 
S to wszystkie narzdzia, kt贸re naladuj ludzkie funkcie poznawcze. Technologie kognitywne potrafi si uczy, wnioskowa, przetwarza jzyk albo obrazy. Cokoliwek co naladuje ludzki umys, jest technologi kognitywn. 

Czy koo zajmuje si analiz medi贸w spoecznociowych? 
Oczywicie, badamy social media przy u偶yciu AI, oraz prowadzimy wasne profile. 

Czy koo zajmuje si badaniami nad sztuczn inteligencj (AI)? 
Tak. To g贸wny cel koa. Eksperymuentujemy g贸wnie z du偶ymi modelami jzykowymi. Szkolimy je, testujemy je pod wieloma ktami. Mamy dostp do wszystkich modeli AI gdy tylko si pojawi, wic mo偶e sprawdza te偶 ich mo偶liwoci. 

Czy ka偶dy w kole peni konkretn rol? 
Nie. Mamy 6 osobowy zarzd, gdzie role s okrelone. Pozostali czownikowie anga偶uj si w projekty, w kt贸rych chc wzi udzia. 

Jakie umiejtnoci mog zdoby bdc czonkiem koa? 
Mo偶esz poszerzy swoj wiedz oraz praktyczne umiejtnoci w zakresie sztucznej intelgiencji oraz medi贸w spoecznociowych. Zajmuejmy si mi.in. Ternowaniem wasnych modeli GPT, tworzeniem bot贸w analizujcych treci w social media i tworzeniem contentu do medi贸w spoecznociowych. 

Jakie s korzyci z przynale偶noci do koa naukowego? 
Bezporedni korzyci jest udzia w projektach. Nauczysz si trenowa GPT, tworzy filmy albo podcasty, bada media spoecznociowe przy u偶yciu AI. Wszystko zale偶y od twoich zainteresowa. Poza tym poznasz ciekawych ludzi, z kt贸rymi bdziesz wsp贸pracowa. 

Jak mog doczy do koa naukowego? 
Po prostu zgo przewodniczcemu tak ch. Doda ci do naszej konwersacji na messengaerze. Tam dowiesz si o spotkaniach i projekatch, kt贸re realizujemy.  

Z kim si mog skontaktowa w sprawie doczenia do koa? 
Z kimkolwiek z zarzdu. Najlepiej skontaktowa si z przewodniczcym, Michaem Mazurkiewiczem. 

Czy 偶eby doczy do koa, musz spenia jakie wymagania? 
Przyjmujemy tylko student贸w. Poza tym nie ma 偶adnych wymaga. 

Czy mog jeszcze doczy do koa? 
Jasne, nowi czonkowie zawsze mile widziani. 

Czy mog doczy na pr贸b, 偶eby zobaczy czy mi si spodoba? 
Oczywicie, mo偶na zrezygnowa w ka偶dej chwili. 

Jak wyglda rezygnacja z czonkostwa w kole, jeli zdecyduj si odej? 
Wystarczy zgosi zarzdowi ch reygnaji. Oni ju偶 zajm si formalnociami.0 

Czym si bd zajmowa/a jako nowy czonek? 

Za ka偶dym razem gdy wystartuje nowy projekt, dowiesz si o tym. Wtedy bdziesz mie mo偶liwo doczenia, a kierownik projektu przedieli ci zadanie. Mo偶esz te偶 zgasza wasne projekty. Jestemy otwarci na pomysy czonk贸w. 

Czy mog by studentem innego kierunku, 偶eby doczy? 
Tak, chtnie przyjmeimy ka偶dego studenta. 

Jak wyglda typowe spotkanie koa? 
Zbieramy si w wyznaczonym miejscu. Od niedawna may wasn siedzib w budynku C Wydziau Organizacji i zarzdzania.  Zarzd koa zazwyczaj ogasza wtedy projekty i wydarzenia zwizane z koem. Czsto odbywaj si r贸wnie偶 gosowania na sprawami, dotyczcymi 偶ycia koa. 

Czy koo wsp贸pracuje z wykadowcami Politechniki lskiej? 
Wsp贸pracujemy przedewszysstkim z naszym opiekunem, dr. Bartomiejem Knosal. Zdarza si, 偶e przy bardziej teoretycznie skomplikowanych przedwsizwiciach kontaktujemy si z innymi naukowcami. 

Gdzie mog znale藕 wicej informacji o dziaalnoci koa? 
Skontaktuj si z zarzdem, oni wiedz najwicej. 

Gdzie mog Was ledzi, 偶eby by na bie偶co z dziaalnoci koa? 
Na naszym Facebooku i Instagramie. 

Ilu czownk贸w ma koa?
Okoo 30, ale cigle roniemy.
                            '''

                            # Send user message and previous conversation history to OpenAI
                            response = openai.ChatCompletion.create(
                                model="gpt-4o-mini",  # Ensure this is the correct model
                                messages=[
                                    {"role": "system", "content": system_prompt},
                                ] + conversation_history[sender_id]
                            )
                            bot_reply = response['choices'][0]['message']['content']

                            # Add the bot's response to the conversation history
                            conversation_history[sender_id].append({"role": "assistant", "content": bot_reply})

                        except Exception as e:
                            print(f"Error occurred while fetching response from OpenAI: {e}")
                            bot_reply = "Przepraszam, wystpi problem. Prosz spr贸bowa ponownie."

                        # Send the response to the user
                        send_message(sender_id, bot_reply)

        return "EVENT_RECEIVED", 200

def send_message(recipient_id, text):
    """Wysya wiadomo do u偶ytkownika"""
    PAGE_ACCESS_TOKEN = os.getenv("PAGE_ACCESS_TOKEN")
    url = f"https://graph.facebook.com/v12.0/me/messages?access_token={PAGE_ACCESS_TOKEN}"
    payload = {
        "recipient": {"id": recipient_id},
        "message": {"text": text}
    }
    headers = {"Content-Type": "application/json"}
    response = requests.post(url, json=payload, headers=headers)
    print(f"Message sent: {response.json()}")

if __name__ == '__main__':
    app.run(debug=True)
